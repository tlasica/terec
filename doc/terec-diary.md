## BACKLOG

1. run.sh should create test/test project and org
2. check what is the source of branch for export-build
3. add test mocking jenkins server to return expected json
4. add details to tests reg _ression-check e.g. failures

### GET CALL for last run of suite and branch

### FAILED_TEST_RUN with HASH

I think we should add failure-hash to the list so that
we can improve user experience e.g. to link issue to test failure.
This means we should have a new table FAIlED_TEST_RUN.
Hash can be generated based on suite run and test case run.

### LINK ISSUE

This should be quite easy if we have FAILED_TEST_RUN,
we can add some link (like jira link or gh link).
We should probably have some new table like:
FAILED_TEST_RUN_ISSUE_LINK with link and timestamp.

### REPORT ISSUE

What we need is to create ticket (gh, jira) with proper content
possibly also links etc. Each project has special requirements
for labeling, summary structure, project etc.

This means we should live it to the caller how to report:
- use templating engine
- use jira lib or gh lib
- maybe tests report-jira or tests report-gh commands?
- with some config file as parameter?

### BUILD URLS

Console cannot show links, if they are cut it sucks.
So if we have failure hash we can use show or open commands.
```tests open xxx``

### CLI for admin

1. create org
2. create project

### API keys-based Authz (Apr 2025)

To support multitenancy or hosting we need to have some way of Authz.

We could do it using TOKENs that are provided by client or generated by system.

Some discussion how to do it:
https://www.perplexity.ai/search/can-you-propose-an-easy-way-to-WyrVX3eSRaCuBEMi51kBdw

Basic functional design:
1. admin api token is generated with create ORG call.
2. new admin api token can be generated to ORG
3. any operation on ORG requires X-API-Key custom http header
4. for PRJ (created using org api token) tokens are generated for WRITE permissions
5. add run/ add tests operations require api-key for project
6. read operations on PRJ do not require api keys
7. multiple write tokens should be available

Notes:
- it would be good to switch security as mandatory via env variable
- security is not required / not returned if not enabled e.g. for tests

## 2023-12-01 Regression Detection

New regression can be based on similarity check or on the history of failures.
This will require some assumption that we collect error details or stacktrace.
We can probably stick to same test case (maybe different configs).

To implement the flow:
1. test failure is imported => event::test_case_run_failed is created
2. a worked picks up this event and analyzes it
3. if a regression is found then an event::test_case_run_regression is created
4. if notification is configured for given suite/branch then slack notification is sent (sensu?)

What we need to implement:
1. similarity check
2. test hash
3. a logic to get history and find similarities
4. an api call to find if has is a regression
5. some message queues solution
6. check what happens if events are not read

## 2025-05-04 run_id problem

In `test_suite_run` run_id is unique within a branch name
not globally. This kind of reflects reality in Jenkins,
where for example PR builts have separate run_id numbers.

But for test case run seems that `run_id` is considered
enough to distinguish test suite run.
Which is opposite to `TestSuiteRun` definition.

We need to make a call:
- make run_id unique within all branch runs
- add branch to `TestCaseRun`


## 2025-03-19

Get back to TEREC after 14 months of break (working for Snowflake).

I have done some refreshements:
- switch to Python 3.12.1
- upgrade `poetry` to 1.8 (should be faster)

### Plan for refreshment:

1. remind myself how it is working / etc.
2. update components / versions
3. enhance documentation (links, how to do things etc)
4. host somewhere? (docker compose likely)
5. add gh actions for black and running tests
6. why it takes so long to run all the tests?
7. dogfooding - use terec for terec tests
8. populate terec from spicedb or some other tool?
9. speed things up?
10. opentelemetry?
11. allow easy import from gh actions?
12. add labels for tests passing etc?

## 2023-11-22

I have used various tools to create nice tables (rich) or plots  in the cli application
inspired by this post:
https://medium.com/@SrvZ/how-to-create-stunning-graphs-in-the-terminal-with-python-2adf9d012131

And it worked well, except I was not really able to create the type of the bar plot I wanted:
with bar height being the count of failed tests. Instead I am getting always height done
proportionally from 0 to 100% of available space.

## 2023-11-18

# instead of UI build typer app and deploy in docker

1. because it is for developers
2. because it is simpler and funny exercise
3. because it will allow people to easily deploy and customize

# TODO


## Done

* PUT to add org
* GET for orgs
* adding tests should be PATCH ? No, POST is fine as we are adding/updating tests
* check if adding suite run fails on non-existing project
* export-tests should flatten tests into single list, maybe extract logic?
* can we create a k6 performance benchmark? NO: at this point we can skip it
* import performance is very low due to no asynchronous loading FIXED by unlogged batches
* generate org and project names as alphanum with - or _ FIXED by using fake.domain_name()
* check if resource name is valid when creating (org, project) FIXED by using pydantic field validators
*

## 2023-10-18

## how to deliver the UI

idea:

## api with FastAPI

[FastAPI](https://fastapi.tiangolo.com/) looks quite promising as simple and performant framework based on conventions.
I am going to give it a try.


## cassandra in docker and cqlengine

Struggling to make things working with Cassandra in docker.
Eventually I went with `pytest-docker` plugin that  allows to start `docker-compose.yml` with fixtures.

I have also started to build database layer using `cqlengine` object-mapper for Cassandra.
It seems to work quite well so far - of course no performance tests yet.

I see some potential issues with lack of the SAI indexing, we will see if it can be solved by proper data model.

I think I will go with something quite simple with efficient and simple database plus logic in the code.

## 2023-10-16

### poetry will be used

https://python-poetry.org/docs/

```bash
sudo apt install python3-pip
sudo pip install poetry
sudo poetry self update
```

### project will be build around polylith architecture

This seems to be a valid choice for the project that will be composed
from multiple microservices or apps.

[Polylith Documentation](https://polylith.gitbook.io/polylith/)
[Python Polylith](https://davidvujic.github.io/python-polylith-docs/)

First we need to install polylith:

```bash
sudo poetry self add poetry-multiproject-plugin
sudo poetry self add poetry-polylith-plugin
```

and then we need to setup workspace

```bash
poetry poly create workspace --name terec --theme loose
```

Nice to read tutorial for the microservices polylith app with REST APIs and queues:
(https://github.com/ttamg/python-polylith-microservices-example)


## Questions

1. how to run pylint on poetry
2. how to run tests on poetry poly?
